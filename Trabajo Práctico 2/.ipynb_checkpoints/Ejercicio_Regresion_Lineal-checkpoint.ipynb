{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T08:19:33.323030Z",
     "start_time": "2018-05-05T08:19:33.308960Z"
    }
   },
   "source": [
    "En este notebook intentaremos predecir cuántas veces será compartido en Redes Sociales un artículo de Machine Learning segun algunas de sus características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción: ¿Cuántas veces será compartido un artículo del Blog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comenzar por Importar y Visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.037886Z",
     "start_time": "2018-05-06T15:28:50.028212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mruizo\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\mruizo\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\mruizo\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.051323Z",
     "start_time": "2018-05-06T15:28:50.040878Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'articulos_ml.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3de1de2c9f30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#cargamos los datos de entrada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"articulos_ml.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'articulos_ml.csv'"
     ]
    }
   ],
   "source": [
    "#cargamos los datos de entrada\n",
    "data = pd.read_csv(\"articulos_ml-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.064402Z",
     "start_time": "2018-05-06T15:28:50.055301Z"
    }
   },
   "outputs": [],
   "source": [
    "#veamos cuantas dimensiones y registros contiene\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.093837Z",
     "start_time": "2018-05-06T15:28:50.068610Z"
    }
   },
   "outputs": [],
   "source": [
    "#son 161 registros con 8 columnas. Veamos los primeros registros para tener una idea\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que algunos campos (por ejemplo en comentarios) tienen valores nulos.\n",
    "\n",
    "En nuestro caso la columna Shares será nuestra salida, es decir nuestro valor \"Y\", el valor que queremos predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.126775Z",
     "start_time": "2018-05-06T15:28:50.097200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ahora veamos algunas estadísticas de nuestros datos\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T08:36:49.122754Z",
     "start_time": "2018-05-05T08:36:49.108512Z"
    }
   },
   "source": [
    "De aqui observamos que por ejemplo la media de Cantidad de palabras es 1808\n",
    "\n",
    "Hay un artíclo mínimo con 250 palabras y el máximo contiene 8401.\n",
    "\n",
    "Y en cuanto a las salidas, vemos mínimo de 0 veces compartido y máximo de 350000 (eso es mucho!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:50:03.185268Z",
     "start_time": "2018-05-06T15:50:02.485816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizamos rápidamente las caraterísticas de entrada\n",
    "data.drop(['Title','url', 'Elapsed days'],1).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos Cantidad de Palabras vs. Compartidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.505154Z",
     "start_time": "2018-05-06T15:28:50.130110Z"
    }
   },
   "outputs": [],
   "source": [
    "#vamos a Visualizar los datos de entrada\n",
    "colores=['orange','blue']\n",
    "tamanios=[30,60]\n",
    "\n",
    "f1 = data['Word count'].values\n",
    "f2 = data['# Shares'].values\n",
    "\n",
    "# Vamos a pintar en 2 colores los puntos por debajo de la media de Cantidad de Palabras\n",
    "asignar=[]\n",
    "for index, row in data.iterrows():\n",
    "    if(row['Word count']>1808):\n",
    "        asignar.append(colores[0])\n",
    "    else:\n",
    "        asignar.append(colores[1])\n",
    "    \n",
    "plt.scatter(f1, f2, c=asignar, s=tamanios[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:50.963199Z",
     "start_time": "2018-05-06T15:28:50.509749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vamos a RECORTAR los datos en la zona donde se concentran más los puntos\n",
    "# esto es en el eje X: entre 0 y 3.500\n",
    "# y en el eje Y: entre 0 y 80.000\n",
    "filtered_data = data[(data['Word count'] <= 3500) & (data['# Shares'] <= 80000)]\n",
    "\n",
    "f1 = filtered_data['Word count'].values\n",
    "f2 = filtered_data['# Shares'].values\n",
    "\n",
    "# Vamos a pintar en colores los puntos por debajo y por encima de la media de Cantidad de Palabras\n",
    "asignar=[]\n",
    "for index, row in filtered_data.iterrows():\n",
    "    if(row['Word count']>1808):\n",
    "        asignar.append(colores[0])\n",
    "    else:\n",
    "        asignar.append(colores[1])\n",
    "    \n",
    "plt.scatter(f1, f2, c=asignar, s=tamanios[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.024042Z",
     "start_time": "2018-05-06T15:28:50.967169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Veamos como cambian los valores una vez filtrados\n",
    "filtered_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal Simple (1 variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a intentar primero una Regresión Lineal con 1 sóla variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.036535Z",
     "start_time": "2018-05-06T15:28:51.027426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Asignamos nuestra variable de entrada X para entrenamiento y las etiquetas Y.\n",
    "dataX =filtered_data[[\"Word count\"]]\n",
    "X_train = np.array(dataX)\n",
    "y_train = filtered_data['# Shares'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.054663Z",
     "start_time": "2018-05-06T15:28:51.042421Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creamos el objeto de Regresión Linear\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Entrenamos nuestro modelo\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Hacemos las predicciones que en definitiva una línea (en este caso, al ser 2D)\n",
    "y_pred = regr.predict(X_train)\n",
    "\n",
    "# Veamos los coeficienetes obtenidos, En nuestro caso, serán la Tangente\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# Este es el valor donde corta el eje Y (en X=0)\n",
    "print('Independent term: \\n', regr.intercept_)\n",
    "# Error Cuadrado Medio\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_train, y_pred))\n",
    "# Puntaje de Varianza. El mejor puntaje es un 1.0\n",
    "print('Variance score: %.2f' % r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos la Recta que obtuvimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.432242Z",
     "start_time": "2018-05-06T15:28:51.060915Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:,0], y_train,  c=asignar, s=tamanios[0])\n",
    "plt.plot(X_train[:,0], y_pred, color='red', linewidth=3)\n",
    "\n",
    "plt.xlabel('Cantidad de Palabras')\n",
    "plt.ylabel('Compartido en Redes')\n",
    "plt.title('Regresión Lineal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.440993Z",
     "start_time": "2018-05-06T15:28:51.435404Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vamos a comprobar:\n",
    "# Quiero predecir cuántos \"Shares\" voy a obtener por un artículo con 2.000 palabras,\n",
    "# según nuestro modelo, hacemos:\n",
    "y_Dosmil = regr.predict([[2000]])\n",
    "print(int(y_Dosmil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente No es tan sencillo...\n",
    "\n",
    "Vamos a mejorar un poco el modelo\n",
    "\n",
    "# Regresión Lineal Múltiples (múltiples variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.462189Z",
     "start_time": "2018-05-06T15:28:51.446341Z"
    }
   },
   "outputs": [],
   "source": [
    "#Vamos a intentar mejorar el Modelo, con una dimensión más: \n",
    "# Para poder graficar en 3D, haremos una variable nueva que será la suma de los enlaces, comentarios e imágenes\n",
    "suma = (filtered_data[\"# of Links\"] + filtered_data['# of comments'].fillna(0) + filtered_data['# Images video'])\n",
    "\n",
    "dataX2 =  pd.DataFrame()\n",
    "dataX2[\"Word count\"] = filtered_data[\"Word count\"]\n",
    "dataX2[\"suma\"] = suma\n",
    "XY_train = np.array(dataX2)\n",
    "z_train = filtered_data['# Shares'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T09:54:24.557815Z",
     "start_time": "2018-05-06T09:54:24.544488Z"
    }
   },
   "source": [
    "Atención: Esta vez, nuestras dimensiones de entrenamiento serán X e Y y las etiquetas de predicción serán z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:51.481430Z",
     "start_time": "2018-05-06T15:28:51.466336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo objeto de Regresión Lineal\n",
    "regr2 = linear_model.LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo, esta vez, con 2 dimensiones\n",
    "# obtendremos 2 coeficientes, para graficar un plano\n",
    "regr2.fit(XY_train, z_train)\n",
    "\n",
    "# Hacemos la predicción con la que tendremos puntos sobre el plano hallado\n",
    "z_pred = regr2.predict(XY_train)\n",
    "\n",
    "# Los coeficientes\n",
    "print('Coefficients: \\n', regr2.coef_)\n",
    "# Error cuadrático medio\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(z_train, z_pred))\n",
    "# Evaluamos el puntaje de varianza (siendo 1.0 el mejor posible)\n",
    "print('Variance score: %.2f' % r2_score(z_train, z_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T09:32:25.955992Z",
     "start_time": "2018-05-06T09:32:25.949240Z"
    }
   },
   "source": [
    "## Esta vez visualizamos un plano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:52.283257Z",
     "start_time": "2018-05-06T15:28:51.489306Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# Creamos una malla, sobre la cual graficaremos el plano\n",
    "xx, yy = np.meshgrid(np.linspace(0, 3500, num=10), np.linspace(0, 60, num=10))\n",
    "\n",
    "# calculamos los valores del plano para los puntos x e y\n",
    "nuevoX = (regr2.coef_[0] * xx)\n",
    "nuevoY = (regr2.coef_[1] * yy) \n",
    "\n",
    "# calculamos los correspondientes valores para z. Debemos sumar el punto de intercepción\n",
    "z = (nuevoX + nuevoY + regr2.intercept_)\n",
    "\n",
    "# Graficamos el plano\n",
    "ax.plot_surface(xx, yy, z, alpha=0.2, cmap='hot')\n",
    "\n",
    "# Graficamos en azul los puntos en 3D\n",
    "ax.scatter(XY_train[:, 0], XY_train[:, 1], z_train, c='blue',s=30)\n",
    "\n",
    "# Graficamos en rojo, los puntos que \n",
    "ax.scatter(XY_train[:, 0], XY_train[:, 1], z_pred, c='red',s=40)\n",
    "\n",
    "# con esto situamos la \"camara\" con la que visualizamos\n",
    "ax.view_init(elev=30., azim=65)\n",
    "        \n",
    "ax.set_xlabel('Cantidad de Palabras')\n",
    "ax.set_ylabel('Cantidad de Enlaces,Comentarios e Imagenes')\n",
    "ax.set_zlabel('Compartido en Redes')\n",
    "ax.set_title('Regresión Lineal con Múltiples Variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T11:28:25.503809Z",
     "start_time": "2018-05-10T11:28:25.499128Z"
    }
   },
   "source": [
    "### Predicción 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:52.296422Z",
     "start_time": "2018-05-06T15:28:52.288285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Si quiero predecir cuántos \"Shares\" voy a obtener por un artículo con: \n",
    "# 2000 palabras y con enlaces: 10, comentarios: 4, imagenes: 6\n",
    "# según nuestro modelo, hacemos:\n",
    "\n",
    "z_Dosmil = regr2.predict([[2000, 10+4+6]])\n",
    "print(int(z_Dosmil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T20:21:38.538763Z",
     "start_time": "2018-05-05T20:21:38.532383Z"
    }
   },
   "source": [
    "## Comparemos las predicciónes obtenidas en los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, Obtuvimos mejora en el modelo de 2 dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:52.309115Z",
     "start_time": "2018-05-06T15:28:52.301926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Restamos los errores calculados antes:\n",
    "# Obviamente, \"menos error\" es mejor\n",
    "mejoraEnError = mean_squared_error(y_train, y_pred) - mean_squared_error(z_train, z_pred)\n",
    "print(mejoraEnError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:52.321109Z",
     "start_time": "2018-05-06T15:28:52.312143Z"
    }
   },
   "outputs": [],
   "source": [
    "# También calculamos la mejora en la varianza:\n",
    "mejoraEnVarianza = r2_score(z_train, z_pred) - r2_score(y_train, y_pred)\n",
    "print(mejoraEnVarianza)\n",
    "# Aunque no parezca mucho, recordemos que el valor más alto que se puede obtener es 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-06T15:28:52.336282Z",
     "start_time": "2018-05-06T15:28:52.326212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalmente, mejoramos en nuestra predicción de un artículo de 2.000 palabras, \n",
    "# pues aunque disminuyen los \"Shares\" que obtendremos en el 2do modelo, \n",
    "# seguramente será un valor más cercano a la realidad\n",
    "diferenciaComparir = z_Dosmil - y_Dosmil\n",
    "print(int(diferenciaComparir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejorar las predicciones y notas finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo utilizamos información de artículos sobre Machine Learning con algunos datos ficticios \n",
    "en nuestro .csv pero si quisieramos tratar de mejorar\n",
    "las predicciones, deberiamos utilizar más de 2 variables (recordemos que aqui lo hicimos para poder\n",
    "graficar en 3D).\n",
    "Sería conveniente además conseguir mejores características de entrada, pues no es lo mismo un enlace\n",
    "de un portal con multitud de visitas al mes, que otros Blogs más modestos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
